#!/usr/bin/perl
use warnings;
use strict;
use threads;
use WWW::Mechanize;
use Thread::Queue;
use threads::shared;
use URI;
use 5.010;

#require 'sql_scanning.pl';
#require 'sql_attack.pl';

my %crawl_urls :shared;

my $url = shift || "Please provide an initial source URL";
my $max_depth = shift || 1;
my $depth :shared=0;
my $keyword = (split /:\/\//, $url)[1];
my $crawl = WWW::Mechanize->new();

eval{ $crawl->get($url) };
$crawl_urls{$url}=1;

my @links = $crawl->find_all_links;
my @urls;

for my $link (@links)
{
    my $url = $link->url_abs();
    next unless $url =~ /$keyword/;
    push @urls, $url;
}

my $queue  = new Thread::Queue(@urls);
$queue->enqueue('--');

my $thr1 = threads->create(\&crawl);
my $thr2 = threads->create(\&crawl);

sub crawl
{
    while($queue->pending()>0 and $max_depth>$depth)
    {
        my $url = $queue->dequeue;

        say $url;
        if($url eq '--')
        {
            $depth++;
            $queue->enqueue('--');
            next;
        }
        next if $crawl_urls{$url};
        $crawl_urls{$url} = 1;
        
        eval{ $crawl->get($url) };
        
        my @links = $crawl->find_all_links;
        for my $link (@links)
        {
            my $url = $link->url_abs();
            next unless $url =~ /$keyword/;
            next if $crawl_urls{$url};
            $queue->enqueue($url);
        }
    }

}

$thr1->join();
$thr2->join();

#for my $url (keys %crawl_urls)
#{
#    next if $url =~ /$keyword/;
#    delete $crawl_urls{$url};
#}

for my $url (keys %crawl_urls)
{
    say "$url";
}

