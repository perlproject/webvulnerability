#!/usr/bin/perl
use warnings;
use strict;
use threads;
use WWW::Mechanize;
use Thread::Queue;
use URI;
use 5.010;

require 'sql_scanning.pl';
require 'sql_attack.pl';

my %crawl_urls;

my $url = shift || "Please provide an initial source URL";
my $max_depth = shift || 1;
my $depth=0;
my $keyword = (split /:\/\//, $url)[1];
my $crawl = WWW::Mechanize->new();

eval{ $crawl->get($url) };
$crawl_urls{$url}=1;

my @links = $crawl->find_all_links;
my @urls;

for my $link (@links)
{
    my $url = $link->url_abs();
    push @urls, $url;
}

my $queue = new Thread::Queue(@urls);
$queue->enqueue('--');

while($queue->pending()>0 and $max_depth>$depth)
{
    my $url = $queue->dequeue;
    if($url eq '--')
    {
        $depth++;
        $queue->enqueue('--');
        next;
    }
    next if $crawl_urls{$url};
    $crawl_urls{$url} = 1;
    
    eval{ $crawl->get($url) };
    
    my @links = $crawl->find_all_links;
    for my $link (@links)
    {
        my $url = $link->url_abs();
        next if $crawl_urls{$url};
        $queue->enqueue($url);
    }
}

for my $url (keys %crawl_urls)
{
    next if $url =~ /$keyword/;
    delete $crawl_urls{$url};
}

for my $url (keys %crawl_urls)
{
    say "$url";
}

open CONFIG, ">TEST";
for my $url (keys %crawl_urls)
{
    print CONFIG $url, $crawl_urls{$url};
}
close CONFIG;

&sql_scanning($crawl, \%crawl_urls);
                   
say "----------------------------------";

for my $url (keys %crawl_urls)
{
    say "$url";
}

say "----------------------------------";
&sql_attack($crawl, \%crawl_urls);
